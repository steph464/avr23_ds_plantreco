{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM9POv19GN2ZeBGqiG/49lm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Importance des poids sur les couches du modèle Vgg16"],"metadata":{"id":"3oP-a1CsgJo_"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EqBifdEweoyG","executionInfo":{"status":"ok","timestamp":1687333630419,"user_tz":-120,"elapsed":11384,"user":{"displayName":"Rick Hornett","userId":"01101869092372229649"}},"outputId":"5e808d68-7849-41c1-ca34-54a5e86c3bcf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 1s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 0\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.applications import VGG16\n","\n","# Charger le modèle pré-entraîné (VGG16)\n","vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n","\n","for layer in vgg16.layers:\n","    layer.trainable = False\n","\n","vgg16.summary()"]},{"cell_type":"markdown","source":["# Test Grad-CAM sur images avec background"],"metadata":{"id":"HFmIrbpOhsj5"}},{"cell_type":"code","source":["import pickle\n","import tensorflow as tf\n","import cv2\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","response = requests.get('https://drive.google.com/uc?export=view&id=1MX2Zz7Q9qGejgkmK5VfwBTkabR2-6soN')\n","img1 = Image.open(BytesIO(response.content))\n","\n","input_shape = (256, 256, 3)\n","\n","# Chargement du modèle\n","model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","\n","# Modèles de gradient pour chaque couche\n","grad_models = [\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_pool').output, model.output])\n","]\n","\n","# Prétraitement de l'image\n","img = img1.resize((256, 256))\n","img = np.array(img) / 255.0\n","img = np.expand_dims(img, axis=0)\n","\n","num_rows = 5\n","num_cols = 4\n","fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n","fig.suptitle('Grad-CAM Visualization', fontsize=16)\n","\n","# Image originale\n","axs[0, 0].imshow(img1)\n","axs[0, 0].set_title('Original Image')\n","axs[0, 0].axis('off')\n","\n","for i, grad_model in enumerate(grad_models):\n","    with tf.GradientTape() as tape:\n","        conv_outputs, predictions = grad_model(img)\n","        label_idx = tf.argmax(tf.squeeze(predictions)).numpy()  # Index de la classe prédite\n","        loss = tf.gather(tf.squeeze(predictions), [label_idx])\n","\n","    output = conv_outputs[0]\n","    grads = tape.gradient(loss, conv_outputs)[0]\n","    gate_f = tf.cast(output > 0, 'float32')\n","    gate_r = tf.cast(grads > 0, 'float32')\n","    guided_grads = gate_f * gate_r * grads\n","    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n","    cam = tf.reduce_sum(tf.multiply(weights, output), axis=-1)\n","    cam = np.maximum(cam, 0)\n","    cam = cv2.resize(cam, (256, 256))\n","    heatmap = cam / np.max(cam)\n","    overlay = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n","    overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n","    gradcam = cv2.addWeighted(np.array(img1), 0.5, overlay, 0.5, 0)\n","\n","    row = (i + 1) // num_cols\n","    col = (i + 1) % num_cols\n","\n","    axs[row, col].imshow(gradcam, cmap='jet')\n","    axs[row, col].set_title(f'block{i+1}_layer')\n","    axs[row, col].axis('off')\n","\n","# Suppression des subplots vides\n","for i in range(len(grad_models) + 1, num_rows * num_cols):\n","    row = i // num_cols\n","    col = i % num_cols\n","    axs[row, col].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ogWql20uGtrpQqFbuX5DP8euI4R_ORkW"},"id":"qIjF_fRBf_Lu","executionInfo":{"status":"ok","timestamp":1687265266422,"user_tz":-120,"elapsed":62121,"user":{"displayName":"Rick Hornett","userId":"01101869092372229649"}},"outputId":"27f20114-6723-455c-ac2a-6117ab64e2b0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"BzS8bJvjMXaL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Apple___healthy"],"metadata":{"id":"JFttM-Z3NhuY"}},{"cell_type":"code","source":["import pickle\n","import tensorflow as tf\n","import cv2\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","response = requests.get('https://drive.google.com/uc?export=view&id=17oggth06ZSBv1v5I4_XGx64gEqyBenf2')\n","img1 = Image.open(BytesIO(response.content))\n","\n","input_shape = (256, 256, 3)\n","\n","# Chargement du modèle\n","model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","\n","# Modèles de gradient pour chaque couche\n","grad_models = [\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_pool').output, model.output])\n","]\n","\n","# Prétraitement de l'image\n","img = img1.resize((256, 256))\n","img = np.array(img) / 255.0\n","img = np.expand_dims(img, axis=0)\n","\n","num_rows = 5\n","num_cols = 4\n","fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n","fig.suptitle('Grad-CAM Visualization', fontsize=16)\n","\n","# Image originale\n","axs[0, 0].imshow(img1)\n","axs[0, 0].set_title('Original Image')\n","axs[0, 0].axis('off')\n","\n","for i, grad_model in enumerate(grad_models):\n","    with tf.GradientTape() as tape:\n","        conv_outputs, predictions = grad_model(img)\n","        label_idx = tf.argmax(tf.squeeze(predictions)).numpy()  # Index de la classe prédite\n","        loss = tf.gather(tf.squeeze(predictions), [label_idx])\n","\n","    output = conv_outputs[0]\n","    grads = tape.gradient(loss, conv_outputs)[0]\n","    gate_f = tf.cast(output > 0, 'float32')\n","    gate_r = tf.cast(grads > 0, 'float32')\n","    guided_grads = gate_f * gate_r * grads\n","    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n","    cam = tf.reduce_sum(tf.multiply(weights, output), axis=-1)\n","    cam = np.maximum(cam, 0)\n","    cam = cv2.resize(cam, (256, 256))\n","    heatmap = cam / np.max(cam)\n","    overlay = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n","    overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n","    gradcam = cv2.addWeighted(np.array(img1), 0.5, overlay, 0.5, 0)\n","\n","    row = (i + 1) // num_cols\n","    col = (i + 1) % num_cols\n","\n","    axs[row, col].imshow(gradcam, cmap='jet')\n","    axs[row, col].set_title(f'block{i+1}_layer')\n","    axs[row, col].axis('off')\n","\n","# Suppression des subplots vides\n","for i in range(len(grad_models) + 1, num_rows * num_cols):\n","    row = i // num_cols\n","    col = i % num_cols\n","    axs[row, col].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1oWVrEeTVBLQCeiScHtkNiC4x92B7VC-9"},"id":"ey9hbsiUocSR","executionInfo":{"status":"ok","timestamp":1687269548772,"user_tz":-120,"elapsed":63130,"user":{"displayName":"Rick Hornett","userId":"01101869092372229649"}},"outputId":"03935d34-c0f8-4e1c-85ef-b724e0e01eff"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Apple___Apple_scab"],"metadata":{"id":"x7W6u-dwNYjI"}},{"cell_type":"code","source":["import pickle\n","import tensorflow as tf\n","import cv2\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","response = requests.get('https://drive.google.com/uc?export=download&id=19c6jMfb-7iX1kWb9HllLxkpN4oI2Mz0s')\n","img1 = Image.open(BytesIO(response.content))\n","\n","input_shape = (256, 256, 3)\n","\n","# Chargement du modèle\n","model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","\n","# Modèles de gradient pour chaque couche\n","grad_models = [\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_pool').output, model.output])\n","]\n","\n","# Prétraitement de l'image\n","img = img1.resize((256, 256))\n","img = np.array(img) / 255.0\n","img = np.expand_dims(img, axis=0)\n","\n","num_rows = 5\n","num_cols = 4\n","fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n","\n","# Image originale\n","axs[0, 0].imshow(img1)\n","axs[0, 0].set_title('Image originale')\n","axs[0, 0].axis('off')\n","\n","for i, grad_model in enumerate(grad_models):\n","    with tf.GradientTape() as tape:\n","        conv_outputs, predictions = grad_model(img)\n","        label_idx = tf.argmax(tf.squeeze(predictions)).numpy()  # Index de la classe prédite\n","        loss = tf.gather(tf.squeeze(predictions), [label_idx])\n","\n","    output = conv_outputs[0]\n","    grads = tape.gradient(loss, conv_outputs)[0]\n","    gate_f = tf.cast(output > 0, 'float32')\n","    gate_r = tf.cast(grads > 0, 'float32')\n","    guided_grads = gate_f * gate_r * grads\n","    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n","    cam = tf.reduce_sum(tf.multiply(weights, output), axis=-1)\n","    cam = np.maximum(cam, 0)\n","    cam = cv2.resize(cam, (256, 256))\n","    heatmap = cam / np.max(cam)\n","    overlay = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n","    overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n","    gradcam = cv2.addWeighted(np.array(img1), 0.5, overlay, 0.5, 0)\n","\n","    row = (i + 1) // num_cols\n","    col = (i + 1) % num_cols\n","\n","    axs[row, col].imshow(gradcam, cmap='jet')\n","    axs[row, col].set_title(f'block{i+1}_layer')\n","    axs[row, col].axis('off')\n","\n","# Suppression des subplots vides\n","for i in range(len(grad_models) + 1, num_rows * num_cols):\n","    row = i // num_cols\n","    col = i % num_cols\n","    axs[row, col].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ASKmk9VIOePZ-s__hOrpHN9aOwbQuAhE"},"id":"uJBHYiKAPowQ","executionInfo":{"status":"ok","timestamp":1687269697718,"user_tz":-120,"elapsed":65397,"user":{"displayName":"Rick Hornett","userId":"01101869092372229649"}},"outputId":"9285b064-7eb4-4527-8435-5e3f1aa35fcf"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Grape___Black_rot"],"metadata":{"id":"1LWMFpKjNwC-"}},{"cell_type":"code","source":["import pickle\n","import tensorflow as tf\n","import cv2\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","response = requests.get('https://drive.google.com/uc?export=download&id=1cL1gFMQEI7jRIJXEcZ4d8k0zIo74xkPq')\n","img1 = Image.open(BytesIO(response.content))\n","\n","input_shape = (256, 256, 3)\n","\n","# Chargement du modèle\n","model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","\n","# Modèles de gradient pour chaque couche\n","grad_models = [\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_pool').output, model.output])\n","]\n","\n","# Prétraitement de l'image\n","img = img1.resize((256, 256))\n","img = np.array(img) / 255.0\n","img = np.expand_dims(img, axis=0)\n","\n","num_rows = 5\n","num_cols = 4\n","fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n","\n","# Image originale\n","axs[0, 0].imshow(img1)\n","axs[0, 0].set_title('Image originale')\n","axs[0, 0].axis('off')\n","\n","for i, grad_model in enumerate(grad_models):\n","    with tf.GradientTape() as tape:\n","        conv_outputs, predictions = grad_model(img)\n","        label_idx = tf.argmax(tf.squeeze(predictions)).numpy()  # Index de la classe prédite\n","        loss = tf.gather(tf.squeeze(predictions), [label_idx])\n","\n","    output = conv_outputs[0]\n","    grads = tape.gradient(loss, conv_outputs)[0]\n","    gate_f = tf.cast(output > 0, 'float32')\n","    gate_r = tf.cast(grads > 0, 'float32')\n","    guided_grads = gate_f * gate_r * grads\n","    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n","    cam = tf.reduce_sum(tf.multiply(weights, output), axis=-1)\n","    cam = np.maximum(cam, 0)\n","    cam = cv2.resize(cam, (256, 256))\n","    heatmap = cam / np.max(cam)\n","    overlay = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n","    overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n","    gradcam = cv2.addWeighted(np.array(img1), 0.5, overlay, 0.5, 0)\n","\n","    row = (i + 1) // num_cols\n","    col = (i + 1) % num_cols\n","\n","    axs[row, col].imshow(gradcam, cmap='jet')\n","    axs[row, col].set_title(f'block{i+1}_layer')\n","    axs[row, col].axis('off')\n","\n","# Suppression des subplots vides\n","for i in range(len(grad_models) + 1, num_rows * num_cols):\n","    row = i // num_cols\n","    col = i % num_cols\n","    axs[row, col].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"15d6Jhy_-aKBYM8olrqsz8J4681Qj-Q5u"},"id":"OMFaS_CTP87b","executionInfo":{"status":"ok","timestamp":1687269795082,"user_tz":-120,"elapsed":66197,"user":{"displayName":"Rick Hornett","userId":"01101869092372229649"}},"outputId":"23d6f25e-ba9c-4944-ae3d-4d6c24ddc961"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Tomato___Leaf_Mold"],"metadata":{"id":"k4KxiyieN4H1"}},{"cell_type":"code","source":["import pickle\n","import tensorflow as tf\n","import cv2\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","response = requests.get('https://drive.google.com/uc?export=download&id=1i8jQhllkUrHbRO9g5jI5sUl2uDyv7Rvz')\n","img1 = Image.open(BytesIO(response.content))\n","\n","input_shape = (256, 256, 3)\n","\n","# Chargement du modèle\n","model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","\n","# Modèles de gradient pour chaque couche\n","grad_models = [\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_pool').output, model.output])\n","]\n","\n","# Prétraitement de l'image\n","img = img1.resize((256, 256))\n","img = np.array(img) / 255.0\n","img = np.expand_dims(img, axis=0)\n","\n","num_rows = 5\n","num_cols = 4\n","fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n","\n","# Image originale\n","axs[0, 0].imshow(img1)\n","axs[0, 0].set_title('Image originale')\n","axs[0, 0].axis('off')\n","\n","for i, grad_model in enumerate(grad_models):\n","    with tf.GradientTape() as tape:\n","        conv_outputs, predictions = grad_model(img)\n","        label_idx = tf.argmax(tf.squeeze(predictions)).numpy()  # Index de la classe prédite\n","        loss = tf.gather(tf.squeeze(predictions), [label_idx])\n","\n","    output = conv_outputs[0]\n","    grads = tape.gradient(loss, conv_outputs)[0]\n","    gate_f = tf.cast(output > 0, 'float32')\n","    gate_r = tf.cast(grads > 0, 'float32')\n","    guided_grads = gate_f * gate_r * grads\n","    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n","    cam = tf.reduce_sum(tf.multiply(weights, output), axis=-1)\n","    cam = np.maximum(cam, 0)\n","    cam = cv2.resize(cam, (256, 256))\n","    heatmap = cam / np.max(cam)\n","    overlay = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n","    overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n","    gradcam = cv2.addWeighted(np.array(img1), 0.5, overlay, 0.5, 0)\n","\n","    row = (i + 1) // num_cols\n","    col = (i + 1) % num_cols\n","\n","    axs[row, col].imshow(gradcam, cmap='jet')\n","    axs[row, col].set_title(f'block{i+1}_layer')\n","    axs[row, col].axis('off')\n","\n","# Suppression des subplots vides\n","for i in range(len(grad_models) + 1, num_rows * num_cols):\n","    row = i // num_cols\n","    col = i % num_cols\n","    axs[row, col].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1WIdWStW3RFUWaMN9fVq6ma3jeiyTFrTL"},"id":"jB_AY9uBPuBJ","executionInfo":{"status":"ok","timestamp":1687269854572,"user_tz":-120,"elapsed":59517,"user":{"displayName":"Rick Hornett","userId":"01101869092372229649"}},"outputId":"5258fb1d-c9ad-43a1-873e-86e7ee04471d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"DIIvf1Y46vOj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"55eESt5x6u_x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","import tensorflow as tf\n","import cv2\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D\n","import gdown\n","\n","response = requests.get('https://drive.google.com/uc?export=download&id=1i8jQhllkUrHbRO9g5jI5sUl2uDyv7Rvz')\n","img1 = Image.open(BytesIO(response.content))\n","\n","input_shape = (256, 256, 3)\n","\n","# Chargement du modèle\n","model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","\n","# Modèles de gradient pour chaque couche\n","grad_models = [\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block1_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block2_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block3_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block4_pool').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv1').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv2').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_conv3').output, model.output]),\n","    tf.keras.models.Model([model.input], [model.get_layer('block5_pool').output, model.output])\n","]\n","\n","# Prétraitement de l'image\n","img = img1.resize((256, 256))\n","img = np.array(img) / 255.0\n","img = np.expand_dims(img, axis=0)\n","\n","num_rows = 5\n","num_cols = 4\n","fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n","\n","# Image originale\n","axs[0, 0].imshow(img1)\n","axs[0, 0].set_title('Image originale')\n","axs[0, 0].axis('off')\n","\n","for i, grad_model in enumerate(grad_models):\n","    with tf.GradientTape() as tape:\n","        conv_outputs, predictions = grad_model(img)\n","        label_idx = tf.argmax(tf.squeeze(predictions)).numpy()  # Index de la classe prédite\n","        loss = tf.gather(tf.squeeze(predictions), [label_idx])\n","\n","    output = conv_outputs[0]\n","    grads = tape.gradient(loss, conv_outputs)[0]\n","    gate_f = tf.cast(output > 0, 'float32')\n","    gate_r = tf.cast(grads > 0, 'float32')\n","    guided_grads = gate_f * gate_r * grads\n","    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n","    cam = tf.reduce_sum(tf.multiply(weights, output), axis=-1)\n","    cam = np.maximum(cam, 0)\n","    cam = cv2.resize(cam, (256, 256))\n","    heatmap = cam / np.max(cam)\n","    overlay = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n","    overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n","    gradcam = cv2.addWeighted(np.array(img1), 0.5, overlay, 0.5, 0)\n","\n","    row = (i + 1) // num_cols\n","    col = (i + 1) % num_cols\n","\n","    axs[row, col].imshow(gradcam, cmap='jet')\n","    axs[row, col].set_title(f'block{i+1}_layer')\n","    axs[row, col].axis('off')\n","\n","# Suppression des subplots vides\n","for i in range(len(grad_models) + 1, num_rows * num_cols):\n","    row = i // num_cols\n","    col = i % num_cols\n","    axs[row, col].axis('off')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","def grad_cam(input_model, image, cls, layer_name):\n","    \"\"\"Méthode GradCAM pour visualiser la saillance de l'entrée.\"\"\"\n","    y_c = input_model.output[0, cls]\n","    conv_output = input_model.get_layer(layer_name).output\n","    grads = tf.gradients(y_c, conv_output)[0]\n","    # Normalisation si nécessaire\n","    # grads = normalize(grads)\n","    gradient_function = tf.function([input_model.input], [conv_output, grads])\n","\n","    output, grads_val = gradient_function([image])\n","    output, grads_val = output[0, :], grads_val[0, :, :, :]\n","\n","    weights = np.mean(grads_val, axis=(0, 1))\n","    cam = np.dot(output, weights)\n","\n","    # Traitement du CAM\n","    cam = cv2.resize(cam, (W, H), cv2.INTER_LINEAR)\n","    cam = np.maximum(cam, 0)\n","    cam = cam / cam.max()\n","    return cam\n","\n","def build_model():\n","    # Construction du modèle principal\n","    input_shape = (256, 256, 3)\n","    model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","\n","    # Ajout des couches supplémentaires\n","    x = model.output\n","    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","    x = tf.keras.layers.Dense(512, activation='relu')(x)\n","    x = tf.keras.layers.Dropout(0.2)(x)\n","\n","    # Construction du modèle final avec les couches ajoutées\n","    model = tf.keras.models.Model(inputs=model.input, outputs=x)\n","\n","    return model\n","\n","    return model\n","\n","def build_guided_model():\n","    # Construction du modèle guidé\n","    guided_model = tf.keras.models.clone_model(build_model())\n","    guided_model.set_weights(build_model().get_weights())\n","\n","    return guided_model\n","\n","def grad_cam_batch(input_model, images, classes, layer_name):\n","    \"\"\"Méthode GradCAM pour visualiser la saillance de l'entrée.\n","    Identique à grad_cam mais traite plusieurs images en une seule exécution.\"\"\"\n","    loss = tf.gather_nd(input_model.output, np.dstack([range(images.shape[0]), classes])[0])\n","    layer_output = input_model.get_layer(layer_name).output\n","    grads = tf.gradients(loss, layer_output)[0]\n","    gradient_fn = tf.function([input_model.input, tf.keras.backend.learning_phase()], [layer_output, grads])\n","\n","    conv_output, grads_val = gradient_fn([images, 0])\n","    weights = np.mean(grads_val, axis=(1, 2))\n","    cams = np.einsum('ijkl,il->ijk', conv_output, weights)\n","\n","    # Traitement des CAMs\n","    new_cams = np.empty((images.shape[0], H, W))\n","    for i in range(new_cams.shape[0]):\n","        cam_i = cams[i] - cams[i].mean()\n","        cam_i = (cam_i + 1e-10) / (np.linalg.norm(cam_i, 2) + 1e-10)\n","        new_cams[i] = cv2.resize(cam_i, (W, H), cv2.INTER_LINEAR)\n","        new_cams[i] = np.maximum(new_cams[i], 0)\n","        new_cams[i] = new_cams[i] / new_cams[i].max()\n","\n","    return new_cams\n","\n","def compute_saliency(model, guided_model, img_path, layer_name='block5_conv3', cls=-1, visualize=True, save=True):\n","    \"\"\"Calcule la saillance en utilisant les trois approches.\n","        -layer_name : couche pour calculer les gradients ;\n","        -cls : numéro de classe à localiser (-1 pour la classe la plus probable).\n","    \"\"\"\n","\n","    url = 'https://drive.google.com/uc?export=download&id=1i8jQhllkUrHbRO9g5jI5sUl2uDyv7Rvz'\n","    output = 'plante.JPG'\n","\n","\n","# Ouvrir l'image avec PIL\n","    image = Image.open(output)\n","    gradcam, gb, guided_gradcam = compute_saliency(model, guided_model, img, layer_name='block5_conv3',\n","                                               cls=-1, visualize=True, save=True)\n","    preprocessed_input = img1                          #load_image(img_path)\n","\n","    predictions = model.predict(preprocessed_input)\n","    top_n = 5\n","    top = decode_predictions(predictions, top=top_n)[0]\n","    classes = np.argsort(predictions[0])[-top_n:][::-1]\n","    print('Prédiction du modèle :')\n","    for c, p in zip(classes, top):\n","        print('\\t{:15s}\\t({})\\tavec une probabilité de {:.3f}'.format(p[1], c, p[2]))\n","    if cls == -1:\n","        cls = np.argmax(predictions)\n","    class_name = decode_predictions(np.eye(1, 1000, cls))[0][0][1]\n","    print(\"Explication pour '{}'\".format(class_name))\n","\n","    gradcam = grad_cam(model, preprocessed_input, cls, layer_name)\n","    gb = guided_backprop(guided_model, preprocessed_input, layer_name)\n","    guided_gradcam = gb * gradcam[..., np.newaxis]\n","\n","    if save:\n","        jetcam = cv2.applyColorMap(np.uint8(255 * gradcam), cv2.COLORMAP_JET)\n","        jetcam = np.float32(jetcam) + load_image(img1, preprocess=False) / 2\n","        cv2.imwrite('gradcam.jpg', np.uint8(jetcam))\n","        cv2.imwrite('guided_backprop.jpg', deprocess_image(gb[0]))\n","        cv2.imwrite('guided_gradcam.jpg', deprocess_image(guided_gradcam[0]))\n","\n","    if visualize:\n","        plt.figure(figsize=(15, 10))\n","        plt.subplot(131)\n","        plt.title('GradCAM')\n","        plt.axis('off')\n","        plt.imshow(load_image(img_path, preprocess=False))\n","        plt.imshow(gradcam, cmap='jet', alpha=0.5)\n","\n","        plt.subplot(132)\n","        plt.title('Guided Backprop')\n","        plt.axis('off')\n","        plt.imshow(np.flip(deprocess_image(gb[0]), -1))\n","\n","        plt.subplot(133)\n","        plt.title('Guided GradCAM')\n","        plt.axis('off')\n","        plt.imshow(np.flip(deprocess_image(guided_gradcam[0]), -1))\n","        plt.show()\n","\n","    return gradcam, gb, guided_gradcam\n","\n","model = build_model()\n","guided_model = build_guided_model()\n","\n","gradcam, gb, guided_gradcam = compute_saliency(model, guided_model, 'cat_dog.png', layer_name='block5_conv3',\n","                                               cls=-1, visualize=True, save=True)\n","gradcam, gb, guided_gradcam = compute_saliency(model, guided_model, 'cat_dog.png', layer_name='block5_conv3',\n","                                               cls=282, visualize=True, save=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"PFJ_EcAW6ut5","executionInfo":{"status":"error","timestamp":1687336870475,"user_tz":-120,"elapsed":9241,"user":{"displayName":"Rick Hornett","userId":"01101869092372229649"}},"outputId":"43111907-7172-45fc-83d9-2d438147a302"},"execution_count":15,"outputs":[{"output_type":"error","ename":"UnidentifiedImageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-39519089f2f0>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://drive.google.com/uc?export=download&id=1i8jQhllkUrHbRO9g5jI5sUl2uDyv7Rvz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3028\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccept_warnings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m     raise UnidentifiedImageError(\n\u001b[0m\u001b[1;32m   3031\u001b[0m         \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m     )\n","\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7f8e4cf01580>"]}]}]}